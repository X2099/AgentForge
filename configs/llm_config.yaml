default_provider: "deepseek-chat"
default_model: "deepseek-chat"

providers:
  deepseek:
    api_key: "${DEEPSEEK_API_KEY}"
    base_url: null
    model_name: "deepseek-chat"
    timeout: 30
    max_retries: 3
    temperature: 0.7
    max_tokens: 2000

  openai:
    api_key: "${OPENAI_API_KEY}"
    base_url: bull
    model_name: "gpt-5"
    timeout: 30
    max_retries: 3
    temperature: 0.7
    max_tokens: 2000

  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: null
    default_model: "claude-3-sonnet"
    timeout: 30
    max_retries: 3
    temperature: 0.7
    max_tokens: 4000

  local:
    default_model: "Qwen/Qwen2.5-7B-Instruct"
    device: "auto"
    load_in_8bit: false
    load_in_4bit: false
    temperature: 0.7
    max_tokens: 512

rate_limiting:
  enabled: true
  requests_per_minute: 60
  tokens_per_minute: 60000

caching:
  enabled: true
  ttl_seconds: 300
  max_size: 100

logging:
  level: "INFO"
  log_file: "./logs/llm.log"
  max_file_size_mb: 10
  backup_count: 5