# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“åˆ›å»ºç»„ä»¶
"""
import streamlit as st
from pathlib import Path
import yaml


class KnowledgeBaseCreator:
    """çŸ¥è¯†åº“åˆ›å»ºç»„ä»¶"""

    def __init__(self, kb_manager):
        self.kb_manager = kb_manager

    def render(self):
        """æ¸²æŸ“åˆ›å»ºçŸ¥è¯†åº“é¡µé¢"""
        st.subheader("ğŸš€ åˆ›å»ºæ–°çŸ¥è¯†åº“")

        # çŸ¥è¯†åº“åŸºæœ¬ä¿¡æ¯
        col1, col2 = st.columns(2)
        with col1:
            kb_name = st.text_input("çŸ¥è¯†åº“åç§°", value="my_knowledge_base")
        with col2:
            kb_description = st.text_input("æè¿°", value="æˆ‘çš„çŸ¥è¯†åº“")

        # å‘é‡å­˜å‚¨é…ç½®
        self._render_vector_config()

        # åµŒå…¥æ¨¡å‹é…ç½®
        self._render_embedder_config()

        # æ–‡æœ¬å¤„ç†é…ç½®
        self._render_text_config()

        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        self._render_file_upload(kb_name)

        # åˆ›å»ºæŒ‰é’®
        self._render_create_button(kb_name, kb_description)

    def _render_vector_config(self):
        """æ¸²æŸ“å‘é‡å­˜å‚¨é…ç½®"""
        st.subheader("ğŸ’¾ å‘é‡å­˜å‚¨é…ç½®")

        vector_config_col1, vector_config_col2 = st.columns(2)

        with vector_config_col1:
            # å‘é‡å­˜å‚¨ç±»å‹
            vector_store_type = st.selectbox(
                "å‘é‡æ•°æ®åº“",
                ["chroma", "faiss", "milvus"],
                format_func=lambda x: {
                    "chroma": "ChromaDB (æ¨è)",
                    "faiss": "FAISS (æœ¬åœ°)",
                    "milvus": "Milvus (ç”Ÿäº§)"
                }[x]
            )

            # åµŒå…¥æ¨¡å‹é…ç½®
            embedder_type = st.selectbox(
                "åµŒå…¥æ¨¡å‹",
                ["openai", "local", "bge"],
                format_func=lambda x: {
                    "openai": "OpenAI Embeddings",
                    "local": "æœ¬åœ° Sentence Transformers",
                    "bge": "BGEä¸­æ–‡æ¨¡å‹"
                }[x]
            )

        with vector_config_col2:
            # å‘é‡å­˜å‚¨ç‰¹å®šé…ç½®
            if vector_store_type == "chroma":
                persist_dir = st.text_input(
                    "æŒä¹…åŒ–ç›®å½•",
                    value=f"./data/vector_stores/{st.session_state.get('kb_name', 'kb')}"
                )
                collection_name = st.text_input("é›†åˆåç§°", value=st.session_state.get('kb_name', 'kb'))

            elif vector_store_type == "faiss":
                index_type = st.selectbox(
                    "ç´¢å¼•ç±»å‹",
                    ["Flat", "IVF", "HNSW"],
                    help="FAISSç´¢å¼•ç®—æ³•"
                )
                nlist = st.number_input("èšç±»æ•°é‡", min_value=1, max_value=10000,
                                        value=100) if index_type == "IVF" else None

            elif vector_store_type == "milvus":
                host = st.text_input("Milvusåœ°å€", value="localhost")
                port = st.number_input("ç«¯å£", min_value=1, max_value=65535, value=19530)
                collection_name = st.text_input("é›†åˆåç§°", value=st.session_state.get('kb_name', 'kb'))

        # å­˜å‚¨é…ç½®åˆ°session state
        st.session_state.vector_config = {
            'store_type': vector_store_type,
            'embedder_type': embedder_type,
            'persist_dir': locals().get('persist_dir'),
            'collection_name': locals().get('collection_name'),
            'host': locals().get('host'),
            'port': locals().get('port'),
            'index_type': locals().get('index_type'),
            'nlist': locals().get('nlist')
        }

    def _render_embedder_config(self):
        """æ¸²æŸ“åµŒå…¥æ¨¡å‹é…ç½®"""
        st.subheader("ğŸ§  åµŒå…¥æ¨¡å‹é…ç½®")

        embed_config_col1, embed_config_col2 = st.columns(2)

        with embed_config_col1:
            embedder_type = st.session_state.vector_config.get('embedder_type', 'bge')

            if embedder_type == "openai":
                openai_key = st.text_input("OpenAI API Key", type="password")
                model_name = st.selectbox(
                    "æ¨¡å‹",
                    ["text-embedding-3-small", "text-embedding-3-large", "text-embedding-ada-002"]
                )
                dimensions = st.number_input(
                    "ç»´åº¦",
                    min_value=256,
                    max_value=3072,
                    value=1536,
                    help="åµŒå…¥å‘é‡ç»´åº¦"
                )

            elif embedder_type == "local":
                model_name = st.selectbox(
                    "æ¨¡å‹åç§°",
                    [
                        "sentence-transformers/all-MiniLM-L6-v2",
                        "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                        "è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„"
                    ]
                )
                if model_name == "è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„":
                    model_name = st.text_input("æ¨¡å‹è·¯å¾„")

            elif embedder_type == "bge":
                model_name = st.selectbox(
                    "BGEæ¨¡å‹",
                    [
                        "BAAI/bge-small-zh-v1.5",
                        "BAAI/bge-base-zh-v1.5",
                        "BAAI/bge-large-zh-v1.5"
                    ]
                )
                normalize_embeddings = st.checkbox("å½’ä¸€åŒ–å‘é‡", value=True)

        with embed_config_col2:
            # é€šç”¨åµŒå…¥é…ç½®
            batch_size = st.number_input(
                "æ‰¹å¤„ç†å¤§å°",
                min_value=1,
                max_value=1000,
                value=32,
                help="æ‰¹é‡å¤„ç†æ–‡æœ¬çš„æ•°é‡"
            )
            device = st.selectbox(
                "è¿è¡Œè®¾å¤‡",
                ["auto", "cpu", "cuda"],
                help="æ¨¡å‹è¿è¡Œè®¾å¤‡ï¼Œautoä¸ºè‡ªåŠ¨é€‰æ‹©"
            )

        # å­˜å‚¨é…ç½®åˆ°session state
        st.session_state.embedder_config = {
            'embedder_type': embedder_type,
            'model_name': locals().get('model_name'),
            'openai_key': locals().get('openai_key'),
            'dimensions': locals().get('dimensions'),
            'normalize_embeddings': locals().get('normalize_embeddings'),
            'batch_size': batch_size,
            'device': device
        }

    def _render_text_config(self):
        """æ¸²æŸ“æ–‡æœ¬å¤„ç†é…ç½®"""
        st.subheader("ğŸ“ æ–‡æœ¬å¤„ç†é…ç½®")

        text_config_col1, text_config_col2 = st.columns(2)

        with text_config_col1:
            # åˆ†å‰²å™¨é…ç½®
            splitter_type = st.selectbox(
                "åˆ†å‰²å™¨ç±»å‹",
                ["recursive", "semantic", "fixed"],
                format_func=lambda x: {
                    "recursive": "é€’å½’åˆ†å‰² (æ¨è)",
                    "semantic": "è¯­ä¹‰åˆ†å‰²",
                    "fixed": "å›ºå®šé•¿åº¦åˆ†å‰²"
                }[x]
            )

            chunk_size = st.number_input(
                "åˆ†å—å¤§å°",
                min_value=100,
                max_value=2000,
                value=500,
                help="æ¯ä¸ªæ–‡æœ¬å—çš„æœ€å¤§å­—ç¬¦æ•°"
            )

        with text_config_col2:
            chunk_overlap = st.number_input(
                "é‡å å¤§å°",
                min_value=0,
                max_value=500,
                value=50,
                help="ç›¸é‚»æ–‡æœ¬å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°"
            )

            if splitter_type == "semantic":
                semantic_threshold = st.slider(
                    "è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.5,
                    help="å¥å­åˆå¹¶çš„ç›¸ä¼¼åº¦é˜ˆå€¼"
                )
                semantic_model = st.selectbox(
                    "è¯­ä¹‰åˆ†å‰²æ¨¡å‹",
                    ["paraphrase-multilingual-MiniLM-L12-v2", "all-MiniLM-L6-v2"]
                )

        # å­˜å‚¨é…ç½®åˆ°session state
        st.session_state.text_config = {
            'splitter_type': splitter_type,
            'chunk_size': chunk_size,
            'chunk_overlap': chunk_overlap,
            'semantic_threshold': locals().get('semantic_threshold'),
            'semantic_model': locals().get('semantic_model')
        }

    def _render_file_upload(self, kb_name):
        """æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ"""
        st.subheader("ğŸ“ ä¸Šä¼ æ–‡æ¡£")

        upload_method = st.radio(
            "ä¸Šä¼ æ–¹å¼",
            ["æœ¬åœ°æ–‡ä»¶ä¸Šä¼ ", "æ–‡ä»¶å¤¹æ‰¹é‡å¯¼å…¥", "ç½‘ç»œé“¾æ¥å¯¼å…¥"]
        )

        file_paths = []

        if upload_method == "æœ¬åœ°æ–‡ä»¶ä¸Šä¼ ":
            uploaded_files = st.file_uploader(
                "é€‰æ‹©æ–‡æ¡£æ–‡ä»¶",
                type=["pdf", "txt", "md", "docx", "html", "csv"],
                accept_multiple_files=True,
                help="æ”¯æŒPDFã€TXTã€Markdownã€Wordã€HTMLã€CSVæ ¼å¼"
            )

            if uploaded_files:
                # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                st.write("å·²é€‰æ‹©æ–‡ä»¶:")
                for uploaded_file in uploaded_files:
                    st.write(f"- {uploaded_file.name} ({uploaded_file.size / 1024:.1f} KB)")

                # ä¿å­˜æ–‡ä»¶
                upload_dir = Path(f"./uploads/{kb_name}")
                upload_dir.mkdir(parents=True, exist_ok=True)

                for uploaded_file in uploaded_files:
                    file_path = upload_dir / uploaded_file.name
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    file_paths.append(str(file_path))

        elif upload_method == "æ–‡ä»¶å¤¹æ‰¹é‡å¯¼å…¥":
            folder_path = st.text_input(
                "æ–‡ä»¶å¤¹è·¯å¾„",
                value="./data/documents",
                help="åŒ…å«æ–‡æ¡£æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„"
            )

            if st.button("æ‰«ææ–‡ä»¶å¤¹"):
                folder = Path(folder_path)
                if folder.exists() and folder.is_dir():
                    # æŸ¥æ‰¾æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶
                    supported_extensions = ['.pdf', '.txt', '.md', '.docx', '.html', '.csv']
                    for ext in supported_extensions:
                        for file in folder.glob(f"**/*{ext}"):
                            file_paths.append(str(file))

                    st.success(f"æ‰¾åˆ° {len(file_paths)} ä¸ªæ–‡æ¡£æ–‡ä»¶")

                    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                    with st.expander("æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨"):
                        for fp in file_paths[:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                            st.write(f"- {Path(fp).name}")
                        if len(file_paths) > 20:
                            st.write(f"... è¿˜æœ‰ {len(file_paths) - 20} ä¸ªæ–‡ä»¶")
                else:
                    st.error("æ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ")

        elif upload_method == "ç½‘ç»œé“¾æ¥å¯¼å…¥":
            urls = st.text_area(
                "è¾“å…¥URLåˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                height=100,
                help="è¾“å…¥æ–‡æ¡£çš„URLé“¾æ¥ï¼Œæ¯è¡Œä¸€ä¸ª"
            )

            if urls:
                url_list = [url.strip() for url in urls.split('\n') if url.strip()]
                file_paths.extend(url_list)
                st.info(f"æ·»åŠ äº† {len(url_list)} ä¸ªç½‘ç»œé“¾æ¥")

        # å­˜å‚¨æ–‡ä»¶è·¯å¾„åˆ°session state
        st.session_state.file_paths = file_paths

    def _render_create_button(self, kb_name, kb_description):
        """æ¸²æŸ“åˆ›å»ºæŒ‰é’®"""
        st.divider()

        file_paths = st.session_state.get('file_paths', [])

        if st.button("ğŸš€ åˆ›å»ºçŸ¥è¯†åº“", type="primary", disabled=not file_paths):
            with st.spinner("æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“..."):
                try:
                    # æ„å»ºé…ç½®
                    kb_config = self._build_kb_config(kb_name, kb_description)

                    # åˆ›å»ºçŸ¥è¯†åº“
                    kb = self.kb_manager.create_knowledge_base(kb_config)

                    # æ·»åŠ æ–‡æ¡£
                    stats = self.kb_manager.bulk_add_documents(
                        kb_name=kb_name,
                        file_paths=file_paths,
                        show_progress=True
                    )

                    # æ˜¾ç¤ºç»“æœ
                    st.success("ğŸ‰ çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸï¼")

                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("å¤„ç†æ–‡ä»¶", stats["processed_files"])
                    with col2:
                        st.metric("å¤±è´¥æ–‡ä»¶", stats["failed_files"])
                    with col3:
                        st.metric("æ€»æ–‡æœ¬å—", stats["total_chunks"])
                    with col4:
                        st.metric("æœ‰æ•ˆå—", stats["valid_chunks"])

                    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                    with st.expander("ğŸ“Š è¯¦ç»†å¤„ç†ç»“æœ"):
                        st.json(stats)

                    # ä¿å­˜é…ç½®
                    self._save_kb_config(kb_config)

                except Exception as e:
                    st.error(f"åˆ›å»ºå¤±è´¥: {str(e)}")
                    st.exception(e)

    def _build_kb_config(self, kb_name, kb_description):
        """æ„å»ºçŸ¥è¯†åº“é…ç½®"""
        vector_config = st.session_state.get('vector_config', {})
        embedder_config = st.session_state.get('embedder_config', {})
        text_config = st.session_state.get('text_config', {})

        kb_config = {
            "name": kb_name,
            "description": kb_description,
            "splitter_type": text_config.get('splitter_type', 'recursive'),
            "chunk_size": text_config.get('chunk_size', 500),
            "chunk_overlap": text_config.get('chunk_overlap', 50),
            "embedder": {
                "embedder_type": embedder_config.get('embedder_type', 'bge'),
                "model": embedder_config.get('model_name', 'BAAI/bge-small-zh-v1.5'),
                "dimensions": embedder_config.get('dimensions'),
                "normalize_embeddings": embedder_config.get('normalize_embeddings'),
                "device": embedder_config.get('device', 'auto')
            },
            "vector_store": {
                "store_type": vector_config.get('store_type', 'chroma'),
                "collection_name": vector_config.get('collection_name', kb_name),
                "persist_directory": vector_config.get('persist_dir', f"./data/vector_stores/{kb_name}"),
                "host": vector_config.get('host'),
                "port": vector_config.get('port')
            }
        }

        # æ·»åŠ è¯­ä¹‰åˆ†å‰²ç‰¹å®šé…ç½®
        if text_config.get('splitter_type') == "semantic":
            kb_config["semantic_threshold"] = text_config.get('semantic_threshold', 0.5)
            kb_config["semantic_model"] = text_config.get('semantic_model', 'paraphrase-multilingual-MiniLM-L12-v2')

        return kb_config

    def _save_kb_config(self, kb_config):
        """ä¿å­˜çŸ¥è¯†åº“é…ç½®"""
        config_dir = Path("./configs/knowledge_bases")
        config_dir.mkdir(parents=True, exist_ok=True)
        config_file = config_dir / f"{kb_config['name']}.yaml"

        with open(config_file, "w", encoding="utf-8") as f:
            yaml.dump(kb_config, f, default_flow_style=False, allow_unicode=True)

        st.info(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_file}")
