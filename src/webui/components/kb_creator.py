# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“åˆ›å»ºç»„ä»¶
"""
import streamlit as st
import requests
from .. import API_BASE_URL


class KnowledgeBaseCreator:
    """çŸ¥è¯†åº“åˆ›å»ºç»„ä»¶"""

    def __init__(self):
        self._vector_store_options = None
        self._embedder_options = None

    def _get_vector_store_options(self):
        """è·å–å‘é‡å­˜å‚¨é€‰é¡¹"""
        if self._vector_store_options is None:
            try:
                response = requests.get(f"{API_BASE_URL}/vector-stores/list", timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    self._vector_store_options = data.get("vector_stores", [])
                else:
                    st.error(f"âŒ è·å–å‘é‡åº“åˆ—è¡¨å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                    st.caption(f"é”™è¯¯è¯¦æƒ…: {response.text}")
                    return
            except Exception as e:
                # ç½‘ç»œé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹
                st.error(f"âŒ è·å–å‘é‡åº“åˆ—è¡¨å¼‚å¸¸ï¼š{e}")
                st.caption(f"é”™è¯¯è¯¦æƒ…: {e}")
                return
        return self._vector_store_options

    def _get_embedder_options(self):
        """è·å–åµŒå…¥å™¨é€‰é¡¹"""
        if self._embedder_options is None:
            try:
                response = requests.get(f"{API_BASE_URL}/embedders/list", timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    self._embedder_options = data.get("embedders", [])
                else:
                    st.error(f"âŒ è·å–embeddingsæ¨¡å‹åˆ—è¡¨å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                    st.caption(f"é”™è¯¯è¯¦æƒ…: {response.text}")
                    return
            except Exception as e:
                # ç½‘ç»œé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹
                st.error(f"âŒ è·å–embeddingsæ¨¡å‹åˆ—è¡¨å¼‚å¸¸ï¼š{e}")
                st.caption(f"é”™è¯¯è¯¦æƒ…: {e}")
        return self._embedder_options

    def render(self):
        """æ¸²æŸ“åˆ›å»ºçŸ¥è¯†åº“é¡µé¢"""
        st.subheader("ğŸš€ åˆ›å»ºæ–°çŸ¥è¯†åº“")

        # çŸ¥è¯†åº“åŸºæœ¬ä¿¡æ¯
        col1, col2 = st.columns(2)
        with col1:
            kb_name = st.text_input("çŸ¥è¯†åº“åç§°", placeholder="åªèƒ½ä½¿ç”¨å­—æ¯ã€æ•°å­—å’Œ_ï¼Œä¸èƒ½ä»¥æ•°å­—å¼€å¤´")
        with col2:
            kb_description = st.text_input("æè¿°", placeholder="çŸ¥è¯†åº“æè¿°")

        # å‘é‡å­˜å‚¨é…ç½®
        self._render_vector_config()

        # åµŒå…¥æ¨¡å‹é…ç½®
        self._render_embedder_config()

        # æ–‡æœ¬å¤„ç†é…ç½®
        self._render_text_config()

        # åˆ›å»ºæŒ‰é’®
        self._render_create_button(kb_name, kb_description)

    def _render_vector_config(self):
        """æ¸²æŸ“å‘é‡å­˜å‚¨é…ç½®"""
        st.subheader("ğŸ’¾ å‘é‡å­˜å‚¨é…ç½®")

        vector_config_col1, vector_config_col2 = st.columns(2)

        with vector_config_col1:
            # è·å–å‘é‡å­˜å‚¨ç±»å‹åˆ—è¡¨
            vector_store_options = self._get_vector_store_options()
            vector_store_type = st.selectbox(
                "å‘é‡æ•°æ®åº“",
                options=[opt["type"] for opt in vector_store_options],
                format_func=lambda x: next((opt["name"] for opt in vector_store_options if opt["type"] == x), x)
            )

        with vector_config_col2:
            # å‘é‡å­˜å‚¨ç‰¹å®šé…ç½®
            if vector_store_type == "chroma":
                collection_name = st.text_input("é›†åˆåç§°", placeholder="ä¸å¡«çš„è¯é»˜è®¤åŒçŸ¥è¯†åº“å")

            elif vector_store_type == "faiss":
                index_type = st.selectbox(
                    "ç´¢å¼•ç±»å‹",
                    ["Flat", "IVF", "HNSW"],
                    help="FAISSç´¢å¼•ç®—æ³•"
                )
                nlist = st.number_input("èšç±»æ•°é‡", min_value=1, max_value=10000,
                                        value=100) if index_type == "IVF" else None

            elif vector_store_type == "milvus":
                host = st.text_input("Milvusåœ°å€", value="localhost")
                port = st.number_input("ç«¯å£", min_value=1, max_value=65535, value=19530)
                collection_name = st.text_input("é›†åˆåç§°", value=st.session_state.get('kb_name', 'kb'))

        # å­˜å‚¨é…ç½®åˆ°session state
        st.session_state.vector_config = {
            'store_type': vector_store_type,
            'persist_dir': locals().get('persist_dir'),
            'collection_name': locals().get('collection_name'),
            'host': locals().get('host'),
            'port': locals().get('port'),
            'index_type': locals().get('index_type'),
            'nlist': locals().get('nlist')
        }

    def _render_embedder_config(self):
        """æ¸²æŸ“åµŒå…¥æ¨¡å‹é…ç½®"""
        st.subheader("ğŸ§  åµŒå…¥æ¨¡å‹é…ç½®")

        embed_config_col1, embed_config_col2 = st.columns(2)

        with embed_config_col1:
            # è·å–åµŒå…¥å™¨ç±»å‹é€‰é¡¹
            embedder_options = self._get_embedder_options()
            embedder_type = st.selectbox(
                "åµŒå…¥æ¨¡å‹ç±»å‹",
                options=[opt["type"] for opt in embedder_options],
                format_func=lambda x: next((opt["name"] for opt in embedder_options if opt["type"] == x), x),
                help="é€‰æ‹©è¦ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹ç±»å‹"
            )

            # è·å–å½“å‰é€‰ä¸­åµŒå…¥å™¨çš„æ¨¡å‹åˆ—è¡¨
            embedder_options = self._get_embedder_options()
            current_embedder = next((opt for opt in embedder_options if opt["type"] == embedder_type), None)

            if current_embedder and "models" in current_embedder:
                # ä»é…ç½®ä¸­è·å–æ¨¡å‹é€‰é¡¹
                model_options = current_embedder["models"]
                model_names = [model["name"] for model in model_options]

                # æ·»åŠ è‡ªå®šä¹‰é€‰é¡¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if embedder_type == "local":
                    model_names.append("è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„")

                model_name = st.selectbox(
                    "æ¨¡å‹",
                    model_names,
                    format_func=lambda x: next(
                        (f'{model["name"]} - {model["description"]}' for model in model_options if model["name"] == x),
                        x),
                    help="é€‰æ‹©è¦ä½¿ç”¨çš„å…·ä½“æ¨¡å‹"
                )

                # å¦‚æœæ˜¯è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„ï¼Œæ˜¾ç¤ºè¾“å…¥æ¡†
                if model_name == "è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„":
                    model_name = st.text_input("æ¨¡å‹è·¯å¾„")

                # æ˜¾ç¤ºæ¨¡å‹ç»´åº¦ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                selected_model_info = next((model for model in model_options if model["name"] == model_name), None)
                if selected_model_info and "dimensions" in selected_model_info:
                    st.info(f"ğŸ“ å‘é‡ç»´åº¦: {selected_model_info['dimensions']}")

            else:
                st.caption(f"æœªè·å–åˆ°æœ‰æ•ˆçš„åµŒå…¥æ¨¡å‹é…ç½®ã€‚")
                return

                # OpenAIç‰¹æœ‰çš„é…ç½®
            if embedder_type == "openai":
                openai_key = st.text_input("OpenAI API Key", type="password")

            # BGEç‰¹æœ‰çš„é…ç½®
            if embedder_type == "bge":
                normalize_embeddings = st.checkbox("å½’ä¸€åŒ–å‘é‡", value=True)

        with embed_config_col2:
            # é€šç”¨åµŒå…¥é…ç½®
            batch_size = st.number_input(
                "æ‰¹å¤„ç†å¤§å°",
                min_value=1,
                max_value=1000,
                value=32,
                help="æ‰¹é‡å¤„ç†æ–‡æœ¬çš„æ•°é‡"
            )
            device = st.selectbox(
                "è¿è¡Œè®¾å¤‡",
                ["cpu", "cuda"],
                help="æ¨¡å‹è¿è¡Œè®¾å¤‡"
            )

        # å­˜å‚¨é…ç½®åˆ°session state
        st.session_state.embedder_config = {
            'embedder_type': embedder_type,
            'model_name': locals().get('model_name'),
            'openai_key': locals().get('openai_key'),
            'dimensions': locals().get('dimensions'),
            'normalize_embeddings': locals().get('normalize_embeddings'),
            'batch_size': batch_size,
            'device': device
        }

    def _render_text_config(self):
        """æ¸²æŸ“æ–‡æœ¬å¤„ç†é…ç½®"""
        st.subheader("ğŸ“ æ–‡æœ¬å¤„ç†é…ç½®")

        text_config_col1, text_config_col2 = st.columns(2)

        with text_config_col1:
            # åˆ†å‰²å™¨é…ç½®
            splitter_type = st.selectbox(
                "åˆ†å‰²å™¨ç±»å‹",
                ["recursive", "semantic", "fixed"],
                format_func=lambda x: {
                    "recursive": "é€’å½’åˆ†å‰² (æ¨è)",
                    "semantic": "è¯­ä¹‰åˆ†å‰²",
                    "fixed": "å›ºå®šé•¿åº¦åˆ†å‰²"
                }[x]
            )

            chunk_size = st.number_input(
                "åˆ†å—å¤§å°",
                min_value=100,
                max_value=2000,
                value=500,
                help="æ¯ä¸ªæ–‡æœ¬å—çš„æœ€å¤§å­—ç¬¦æ•°"
            )

        with text_config_col2:
            chunk_overlap = st.number_input(
                "é‡å å¤§å°",
                min_value=0,
                max_value=500,
                value=50,
                help="ç›¸é‚»æ–‡æœ¬å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°"
            )

            if splitter_type == "semantic":
                semantic_threshold = st.slider(
                    "è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.5,
                    help="å¥å­åˆå¹¶çš„ç›¸ä¼¼åº¦é˜ˆå€¼"
                )
                semantic_model = st.selectbox(
                    "è¯­ä¹‰åˆ†å‰²æ¨¡å‹",
                    ["paraphrase-multilingual-MiniLM-L12-v2", "all-MiniLM-L6-v2"]
                )

        # å­˜å‚¨é…ç½®åˆ°session state
        st.session_state.text_config = {
            'splitter_type': splitter_type,
            'chunk_size': chunk_size,
            'chunk_overlap': chunk_overlap,
            'semantic_threshold': locals().get('semantic_threshold'),
            'semantic_model': locals().get('semantic_model')
        }

    def _render_create_button(self, kb_name, kb_description):
        """æ¸²æŸ“åˆ›å»ºæŒ‰é’®"""
        st.divider()

        if st.button("ğŸš€ åˆ›å»ºçŸ¥è¯†åº“", type="primary"):
            with st.spinner("æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“..."):
                try:
                    # æ„å»ºé…ç½®
                    kb_config = self._build_kb_config(kb_name, kb_description)
                    # è°ƒç”¨APIåˆ›å»ºç©ºçš„çŸ¥è¯†åº“
                    payload = {
                        "kb_name": kb_name,
                        "kb_desc": kb_description,
                        "splitter_type": kb_config["splitter_type"],
                        "chunk_size": kb_config["chunk_size"],
                        "chunk_overlap": kb_config["chunk_overlap"],
                        "embedder": kb_config["embedder"],
                        "vector_store": kb_config["vector_store"],
                        "semantic_config": kb_config.get("semantic_config", {})
                    }

                    response = requests.post(f"{API_BASE_URL}/knowledge_base/create", json=payload, timeout=60)

                    if response.status_code == 200:
                        result = response.json()

                        # æ˜¾ç¤ºç»“æœ
                        st.success("ğŸ‰ çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸï¼")
                        st.info("ğŸ’¡ çŸ¥è¯†åº“å·²åˆ›å»ºå®Œæˆï¼Œæ‚¨å¯ä»¥åœ¨'ä¸Šä¼ æ–‡ä»¶'é¡µé¢ä¸­æ·»åŠ æ–‡æ¡£ã€‚")

                        # æ˜¾ç¤ºçŸ¥è¯†åº“ä¿¡æ¯
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("çŸ¥è¯†åº“åç§°", result["kb_name"])
                        with col2:
                            st.metric("åˆå§‹æ–‡æ¡£æ•°", result["document_count"])

                        # åˆ·æ–°çŸ¥è¯†åº“åˆ—è¡¨
                        st.rerun()

                    else:
                        st.error(f"åˆ›å»ºå¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                        st.caption(f"é”™è¯¯è¯¦æƒ…: {response.text}")

                except requests.exceptions.Timeout:
                    st.error("â° åˆ›å»ºè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
                except requests.exceptions.ConnectionError:
                    st.error("ğŸŒ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ")
                except Exception as e:
                    st.error(f"âŒ åˆ›å»ºå‡ºé”™: {str(e)}")
                    st.caption("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–è”ç³»ç®¡ç†å‘˜")

    def _build_kb_config(self, kb_name, kb_description):
        """æ„å»ºçŸ¥è¯†åº“é…ç½®"""
        vector_config = st.session_state.get('vector_config', {})
        embedder_config = st.session_state.get('embedder_config', {})
        text_config = st.session_state.get('text_config', {})

        kb_config = {
            "name": kb_name,
            "description": kb_description,
            "splitter_type": text_config.get('splitter_type'),
            "chunk_size": text_config.get('chunk_size'),
            "chunk_overlap": text_config.get('chunk_overlap'),
            "embedder": {
                "embedder_type": embedder_config.get('embedder_type'),
                "model": embedder_config.get('model_name'),
                "dimensions": embedder_config.get('dimensions'),
                "normalize_embeddings": embedder_config.get('normalize_embeddings'),
                "device": embedder_config.get('device', 'cpu')
            },
            "vector_store": {
                "store_type": vector_config.get('store_type', 'chroma'),
                "collection_name": vector_config.get('collection_name', kb_name),
                "host": vector_config.get('host'),
                "port": vector_config.get('port')
            }
        }

        # æ·»åŠ è¯­ä¹‰åˆ†å‰²ç‰¹å®šé…ç½®
        if text_config.get('splitter_type') == "semantic":
            kb_config["semantic_config"] = {
                "semantic_threshold": text_config.get('semantic_threshold', 0.5),
                "semantic_model": text_config.get('semantic_model', 'paraphrase-multilingual-MiniLM-L12-v2')
            }

        return kb_config
